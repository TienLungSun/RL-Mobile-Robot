================================= (I) Build a test scene ====================================================================
1. One scene with more obstacles

2. Remove "Decision Requester" component (we will manually do decision request)

3. Import a trained NN model (e.g., MobileRobot.onnx) to project

4. Behavior Parameters
      Model -> Assign a trained NN model
      Behavior type -> Inference only
      
5. Create your own Agent script
      see "Car_Agent_s8.cs" at my https://github.com/TienLungSun/RL-Mobile-Robot
      Start() - run ONLY ONCE when we Play in Unity
      OnEpisodeBegin() - run every time we start a new training session
      Update() - run every game frame
          if the agent reach goal -> stop action
          else run RequestDecision() to call NN to perform actions
      DetermineStage() - determine the agent's stage (1, 2, 3) based on its relative position with the goal
      CollectObservations() - (1, 0, 0, facing angle, d1, d2, ..., d18), (0, 1, 0, 0, d1-d18), (0, 0, 1, 0, d1-d18)
      OnActionReceived(vectorAction) - 
           1. Perform actions
           2. record (t, x, y)
           
6. Save your script and assign public variables

7. Play 

8. Examine the output data file

================================= (II) Experiment with NN structure ====================================================================
1. Open MobileRobot.yaml 

2. max. steps -> 2M

3. NN (3, 512) -> (2, 128)

4. Train 

5. Examine tensorboard (reward, episode, value loss, actor loss) 

6. Test the trained NN model

================================= (III) How NN interacts with the training VE  ====================================================================
time horizon, buffer size (1000, 20480) -> (500, 10000)

================================= (IV) Reward engineering  =========================================================================================
every step -0.005*stage
reach goal: +100, finish training session, start a new training
hit wall or blocks: -0.5, DO NOT FINISH TRAINING
